---
title: "Bootstrap (Part 4)"
author: "Christof Seiler"
date: "Stanford University, Spring 2016, Stats 205"
output:
  beamer_presentation:
    incremental: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
set.seed(1234)
```

## Overview

* So far we used three different bootstraps:
    * Nonparametric bootstrap on the rows (e.g. regression, PCA with random rows and columns)
    * Nonparametric bootstrap on the residuals (e.g. regression)
    * Parametric bootstrap (e.g. PCA with fixed rows and columns)
    * Studentized bootstrap
* Today:
    * Bias correction using the boostrap
    * Bias-corrected-accelerated BCa bootstrap

## Bias Correction in General

TODO and have a look Peter Hall's bias correction for nonlinear regression

## Bias-Corrected Bootstrap

* The bias-corrected bootstrap is similar to the percentile bootstrap
* Recall the percentile bootstrap:
* Take bootstrap samples $$\hat{\theta}^{*1},\dots,\hat{\theta}^{*B}$$
* Order them $$\hat{\theta}^{(*1)},\dots,\hat{\theta}^{(*B)}$$
* Define interval as $$(\hat{\theta}^{(*B\alpha)},\hat{\theta}^{(*B(1-\alpha))})$$ (assuming that $B\alpha$ and $B(1-\alpha)$ are integers)

## Bias-Corrected Bootstrap

* The bias-corrected version makes two additional corrections to the percentile version
* By redefining lower $\alpha_1$ and upper $\alpha_2$ levels as
$$\alpha_1 = \Phi\left(\hat{z}_0 + \frac{\hat{z}_0+z^{(\alpha)}}{1-\hat{\alpha}(\hat{z}_0+z^{(\alpha)})}\right)$$
$$\alpha_2 = \Phi\left(\hat{z}_0 + \frac{\hat{z}_0+z^{(1-\alpha)}}{1-\hat{\alpha}(\hat{z}_0+z^{(1-\alpha)})}\right)$$
with $z^{(\alpha)}$ being the 100$\alpha$ percentile of standard normal  
and $\Phi$ normal CDF
* The interval is then given by
$$(\hat{\theta}^{(*B\alpha_1)},\hat{\theta}^{(*B\alpha_2)})$$ (assuming that $B\alpha_1$ and $B\alpha_2$ are integers)
* When $\hat{a}$ and $\hat{z}_0$ are equal to zero then $\alpha_1=\alpha$ and $\alpha_2=1-\alpha$

## Bias-Corrected Bootstrap

* $\hat{z}_0$ measures discrepancy between the median of $\hat{\theta}^*$ and $\hat{\theta}$
* It is estimated with
$$\hat{z}_0 = \Phi^{-1} \left( \frac{\#\{ \hat{\theta}^{*b} < \hat{\theta} \}}{B} \right)$$
* We obtain $\hat{z}_0 = 0$ if half of the $\hat{\theta}^{*b}$ values are less than or equal to $\hat{\theta}$

## Bias-Corrected Bootstrap

* $\hat{a}$ measures the rate of change of the standard error of $\hat{\theta}$ with respect to the true parameter $\theta$
* It is estimated using the Jackknife
    * Delete $i$th observation in original sample denote new sample by $\hat{\theta}_{(i)}$ and estimate 
$$\hat{\theta}_{(\cdot)} = \sum_{i=1}^n \frac{\hat{\theta}_{(i)}}{n}$$
* Then 
$$\hat{a} = \frac{\sum_{i=1}^n (\hat{\theta}_{(\cdot)}-\hat{\theta}_{(i)})^3}{6\{\sum_{i=1}^n (\hat{\theta}_{(\cdot)}-\hat{\theta}_{(i)})^2\}^{3/2}}$$
* Same accuracy as the studentized bootstrap
* Can handle out of range problem as well
* Efron (1987) for more details

<!--
## Bias-Corrected Bootstrap

* The bias-corrected bootstrap is based on this model
$$\frac{\hat{\phi}-\phi}{\sigma_{\phi}} \sim N(-z_0,1) \hspace{0.5cm} \text{with} \hspace{0.5cm} \sigma_{\phi} = \sigma_{\phi_0} \cdot \left( 1+a(\phi-\phi_0) \right)$$
with $\phi$ being uknown monotone increasing transformation of $\theta$
* Which is a generalization of the usual normal approximation
$$\frac{\hat{\theta}-\theta}{\sigma} \sim N(0,1)$$
* Efron (1987) for justification of this model
-->

## Bias-Corrected Bootstrap in R

```{r echo=TRUE}
library(bootstrap)
xdata = matrix(rnorm(30),ncol=2); n = 15
theta = function(x,xdata) { 
  cor(xdata[x,1],xdata[x,2]) 
  }
results = bcanon(1:n,100,theta,xdata,
                 alpha=c(0.025, 0.975))
results$confpoints
```

<!--
don't need it, computers are fast enough today

## Accelerated Bias-Corrected Bootstrap

TODO: Chapter 14
-->

## Guidelines When to Use Which Boostrap

TODO? The paper that I saw from Isreal

## References

* Efron (1987). Better Bootstrap Confidence Intervals
* Hall (1992). The Bootstrap and Edgeworth Expansion
* Efron and Tibshirani (1994). An Introduction to the Bootstrap

<!--
* Fisher and Hall (1989). Bootstrap Confidence Regions for Directional Data
* Fisher, Hall, Jing, and Wood (1996). Pivotal Methods for Constructing Confidence Regions With Directional Data
-->
