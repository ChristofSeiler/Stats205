---
title: "Signed Test and Signed-Rank Wilcoxon"
author: "Christof Seiler"
date: "Stanford University, Spring 2016, STATS 205"
output:
  ioslides_presentation:
    incremental: yes
    smaller: no
    transition: faster
    widescreen: yes
  beamer_presentation:
    incremental: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Sign Test

* Comparison of ice cream brands A and B
* Blindfolded taster gives preference of one ice cream over the other
* Experiment with 12 taster
    + 10 tasters prefer brand A over brand B
    + 1 taster prefers brand B over A
    + 1 no preference
* Pretty convincing evidence in favor of brand A
* But how likely is such a result due to chance if the null hypothesis is true (no preference in brands)?
* A *null hypothesis* a hypothesis associated with a contradiction to a theory one would like to prove

## Sign Test

* To every statistical test such as the sign test, we associate a *test statistic*
* A test *statistic* is a function of the data
* A *parameter* is a function of the probability distribution
* For this sign test, define the test statistic $S$ is the number positive signs
* Evaluated on our data the observed test statistic is $10$
* We compare the observed test statistic with the null distribution 
* The null distribution is the distribution of the statistic given the null hypothesis is true

## Sign Test

* Under the null hypothesis $S$ is distributed according to a binomial distribution with success probability $1/2$
* The binomial distribution is the number of success in a sequene of $n$ independent trials with success probability $p$
* A two-sided $p$-value can be calculated
* Two-sided: probability of landing in the tails on either side of null distribution  
* One-sided: probability of landing on one side of null distribution

## Sign Test

Evaluate the probability of $10$ successes in $11$ trials with success probability $1/2$
```{r echo=FALSE}
S = 10; n = 11; p = 1/2; 2*dbinom(x = 10,size = 11,prob = p)
```

```{r}
x = seq(0,n,1)
colors = rep("white",length(x))
colors[x >= S] = "red"
barplot(dbinom(x,n,1/2),
        names.arg = x,
        main = paste0("dbinom(x,n = ", n, ",p = ",p,")"),
        col = colors)
```

## Location Model

* $X_1,X_2,\dots,X_n$ denotes random sample following the model
$$ X_i = \theta + e_i, $$
random errors $e_i$ are independently and identically distributed with a continuous probability density function $f(t)$ symmetric around $0$.

* We test hypothesis:
$$ H_0: \theta = 0 \text{ versus } H_A: \theta > 0 $$

## Distribution-Free

* The sign test has test statistic: 
$$ S = \sum_{i_1}^n \operatorname{sign}(X_i) $$
* Looking just at the positive observations: 
$$ S^+ = \#_i \{ X_i > 0 \} $$
* As mentioned before $S^+$ follows a binomical distribution with $n$ trials and success probability $1/2$
* Thus it doesn't depend on the error distribution
* This property is called **distribution-free**

## Traditional $t$-Test

* The $t$-test depends on the population pdf of $f(t)$ 
* Thus it is not distribution free
* The usual test statistic is 
$$ t = \frac{\bar{X}}{s/\sqrt{n}} $$
here $\bar{X}$ is the mean and $s$ is the standard deviation of the sample
* Usually $s$ is not known and has to be estimated, then if the population is normal $t$ has a Student $t$-distribution with $n-1$ degress of freedom
* And the $p$-value $P_{H_0}(t \ge t_0) = 1 - F_T(t_0,n-1)$

## Sign-Rank Wilcoxon Test

* In contrast to the $t$-test, the sign-rank Wilcoxon test uses only the ranks of the distance from $0$
$$ W = \sum_{i>0}^n \operatorname{sign}(X_i) \operatorname{R} |X_i| $$
* No closed-form, iterative algorithms, e.g. ``psignrank`` in R
* Our test statistics considers positive items only
$$ W^+ = \sum_{X_i > 0} \operatorname{R} |X_i| = \frac{1}{2} W + \frac{n(n+1)}{4} $$
* The distribution is symmetric around $\frac{n(n+1)}{4}$

## Signed-Rank Wilcoxon Test

* Question: Does sending kids to school improve social awareness over home schooling?
* Eight pairs of identical twins who are of nursery school age. 
* For each pair, one is randomly selected to attend nursery school while the other remains at home.  
* At the end of the study period, all 16 children are given the same social awareness test.

## Statistic

Calculate ranks of absolute values:

```{r echo=TRUE}
school = c(82,69,73,43,58,56,76,65); home = c(63,42,74,37,51,43,80,62)
response = school - home
response
rank(abs(response))
```

The statistic is the sum of the ranks of positive items:

## Statistic

Calculate ranks of absolute values:

```{r echo=TRUE}
response
rank(abs(response))
```

The statistic is the sum of the ranks of positive items:

```{r}
wplus = sum((response>0)*rank(abs(response)))
wplus
```

## Null Distribution of Test Statistic

Is this due to chance?  

The distribution of test statistic cannot be obtained in closed-form.

Enumerate all possible outcomes for sample size three $n = 3$:

## Null Distribution of Test Statistic

Is this due to chance?  

The distribution of test statistic cannot be obtained in closed-form.

Enumerate all $2^n$ possible outcomes for sample size three $n = 3$:

```{r message=FALSE}
library(R.utils)
sign = intToBin(0:7)
sign = sapply(sign,function(i) c(substr(i,1,1),substr(i,2,2),substr(i,3,3)) )
sign = t(matrix(as.integer(sign),nrow = 3))
rank = t(matrix(rep(1:3,8),nrow = 3))
data.frame(sign=sign)
```

## Null Distribution of Test Statistic

```{r echo = TRUE}
outcome = data.frame(sign=sign,sum=apply(sign*rank,1,sum)); outcome
table(outcome$sum)
```

## Null Distribution of Test Statistic

Or through Monte Carlo simulations:

```{r echo = TRUE}
n = 3; nsim = 10000
X = matrix(rnorm(n*nsim),ncol=n)
WplusSim = apply(X,1, function(x) { r = rank(abs(x)); sum(r * (x>0)) })
table(WplusSim)/nsim
```

and compare with theoretical result:

```{r echo=FALSE}
prop = c(1/8,1/8,1/8,2/8,1/8,1/8,1/8)
names(prop) = 0:6
prop
```

## Computations

Now back to our school example.

```{r echo=FALSE}
n = length(response)
x = seq(0,n*(n+1)/2,1)
colors = rep("white",length(x))
colors[x >= wplus] = "red"
barplot(dsignrank(x,n),names.arg = x,main = paste0("dsignrank(x, n = ", n, ")"),col = colors)
```

## Computations

and using the cumulative distribution function $F_{W^+}(w^+-1,n)$ of our test statistic:

```{r}
plot(x,psignrank(x, n = n),type = "s",main = paste0("psignrank(x, n = ", n, ")"))
abline(v=wplus,col = "red"); abline(h=psignrank(wplus,n),col = "blue")
```

## Computations

we can find the $p$-value using $P_{H_0}(W^+ \ge w^+) = 1 - F_{W^+}(w^+ - 1,n)$:

```{r echo=TRUE}
pvalue = 1-psignrank(wplus-1,n,lower.tail = TRUE)
pvalue
```

### Conclusion

Significance *level*: the probabilty of rejecting the null when it is **true**

We can reject the null hypothesis at significance level $\alpha = 0.05$ in favor of the alternative that sending kids to school improves their social awareness.

## Estimation and Confidence Intervals

* All three estimates (sign test, signed-rank Wilcoxon, and $t$-test) have an associated estimate and confidence interval for the location parameter $\theta$
* Recall the model for our sample $X_1,X_2,\dots,X_n$ 
$$ X_i = \theta_i + e_i $$

* Some definitions:
* *order statistics*: $X_{(1)}$ minimum sample and $X_{(n)}$ the largest
* thus $X_{(1)} < X_{(2)} < \dots < X_{(n)}$
* *quantiles*: equally spaced splitting points of continuous intervals with equal probabalities or sample

## Estimation and Confidence Intervals of Sign Test

Estimator is the median:
$$ \hat{\theta} = \operatorname{median}\{ X_1,X_2,\dots,X_n \} $$

Confidence interval $(1−\alpha)100\%$:
$$ \left(X_{(c_1+1)},X_{(n−c_1)} \right), $$ 
where $c_1$ is the $\frac{\alpha}{2}$ quantile of the binomial distribution

## Estimation and Confidence Intervals of Sign-Rank Wilcoxon

Hodges–Lehmann estimator:
$$ \hat{\theta} = \operatorname{median}_{i\le j} \left\{ \frac{X_i+X_j}{2} \right\} $$

$A{ij} = \frac{(X_i +X_j)}{2}, i \le j$ are called the Walsh averages 

and used to form confidence interval $(1−\alpha)100\%$:
$$ \left(A_{(c_2 +1)},A_{([n(n+1)/2]−c_2 )} \right), $$
$c_2$ is the $\frac{\alpha}{2}$ quantile of the signed-rank Wilcoxon distribution

## Some Comparisons

* *Power* of statistical test:  
the probability of rejection the null hypothesis when it is **false**
* The power of thesign test can be low relative to $t$-test
* The power of signed-rank Wilcoxon test is nearly that of the $t$-test for normal distributions and generally greater than that of the $t$-test for distributions with heavier tails than the normal distribution

## Power Simulation $\theta = 0$

```{r echo=TRUE}
n = 30; df = 2; nsims = 10000; mu = 0; collwil = rep(0,nsims); collt = rep(0,nsims)
for(i in 1:nsims) {
  x = rt(n,df) + mu
  wil = wilcox.test(x) 
  collwil[i] = wil$p.value 
  ttest = t.test(x) 
  collt[i] = ttest$p.value
}
powwil = rep(0,nsims); powwil[collwil <= .05] = 1; powerwil = sum(powwil)/nsims
powt = rep(0,nsims); powt[collt <= .05] = 1; powert = sum(powt)/nsims
powerwil
powert
```

## Power Simulation $\theta = 0.5$

```{r echo=TRUE}
n = 30; df = 2; nsims = 10000; mu = 0.5; collwil = rep(0,nsims); collt = rep(0,nsims)
for(i in 1:nsims) {
  x = rt(n,df) + mu
  wil = wilcox.test(x) 
  collwil[i] = wil$p.value 
  ttest = t.test(x) 
  collt[i] = ttest$p.value
}
powwil = rep(0,nsims); powwil[collwil <= .05] = 1; powerwil = sum(powwil)/nsims
powt = rep(0,nsims); powt[collt <= .05] = 1; powert = sum(powt)/nsims
powerwil
powert
```

## Power Simulation $\theta = 1$

```{r echo=TRUE}
n = 30; df = 2; nsims = 10000; mu = 1; collwil = rep(0,nsims); collt = rep(0,nsims)
for(i in 1:nsims) {
  x = rt(n,df) + mu
  wil = wilcox.test(x) 
  collwil[i] = wil$p.value 
  ttest = t.test(x) 
  collt[i] = ttest$p.value
}
powwil = rep(0,nsims); powwil[collwil <= .05] = 1; powerwil = sum(powwil)/nsims
powt = rep(0,nsims); powt[collt <= .05] = 1; powert = sum(powt)/nsims
powerwil
powert
```
