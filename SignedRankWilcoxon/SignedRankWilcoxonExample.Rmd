---
title: "Signed-Rank Wilcoxon Example"
author: "Christof Seiler"
date: "Stanford University, Spring 2016, STATS 205"
output: 
  ioslides_presentation: 
    incremental: yes
    smaller: yes
    transition: faster
    widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question

Does sending kids to school improve social awareness over home schooling?

## Experiment

Eight pairs of identical twins who are of nursery school age.  
For each pair, one is randomly selected to attend nursery school while the other remains at home.  
At the end of the study period, all 16 children are given the same social awareness test.

```{r}
school = c(82,69,73,43,58,56,76,65)
home = c(63,42,74,37,51,43,80,62)
```

## Differences

For each pair, the response of interest is the difference in the twinsâ€™ scores:

```{r}
school
home
response = school - home
response
```

## Model

* $X_1,X_2,\dots,X_n$ denotes random sample following the model
$$ X_i = \theta + e_i, $$
random errors are independently and identically distributed with a continuous probability density function $f(t)$ symmetric around $0$.

* We test hypothesis:
$$ H_0: \theta = 0 \text{ versus } H_A: \theta > 0 $$
The null distribution of the test statistic does not depend on $f(t)$

## Ranks

Calculate ranks of absolute values:

```{r}
response
abs(response)
rank(abs(response))
```

## Statistic

We use signed-rank Wilcoxon procedure to find out.  
The usual statistic is the sum of the ranks of positive items:

```{r}
wplus = sum((response>0)*rank(abs(response)))
wplus
```

<!--
or equivalently:

```{r}
n = length(response)
w = sum(sign(response)*rank(abs(response)))
wplus = 0.5*w + n*(n+1)/4
wplus
```
-->

## Null Distribution of Test Statistic

Is this due to chance?  
Luckily, the probability mass function for our test statistic is known.  
To see this, let's look at an even simpler example of only three differences, with 8 possible outcomes:

```{r message=FALSE}
library(R.utils)
sign = intToBin(0:7)
sign = sapply(sign,function(i) c(substr(i,1,1),substr(i,2,2),substr(i,3,3)) )
sign = t(matrix(as.integer(sign),nrow = 3))
rank = t(matrix(rep(1:3,8),nrow = 3))
data.frame(sign=sign,rank=rank)
```

## Null Distribution of Test Statistic

```{r}
outcome = data.frame(sign=sign,rank=rank,mul=sign*rank,sum=apply(sign*rank,1,sum))
outcome
table(outcome$sum)
```

## Null Distribution of Test Statistic

Or through Monte Carlo simulations:

```{r}
n = 3; nsim = 10000
X = matrix(rnorm(n*nsim),ncol=n)
WplusSim = apply(X,1, function(x) { r = rank(abs(x)); sum(r * (x>0)) })
table(WplusSim)/nsim
```

and compare with theoretical result:

```{r echo=FALSE}
prop = c(1/8,1/8,1/8,2/8,1/8,1/8,1/8)
names(prop) = 0:6
prop
```

## Computations

Now back to our "more complicated" school example.

```{r eval=FALSE}
n = length(response)
x = seq(0,n*(n+1)/2,1)
colors = rep("white",length(x))
colors[x >= wplus] = "red"
barplot(dsignrank(x,n),
        names.arg = x,
        main = paste0("dsignrank(x, n = ", n, ")"),
        col = colors)
```

## Computations

```{r echo=FALSE}
n = length(response)
x = seq(0,n*(n+1)/2,1)
colors = rep("white",length(x))
colors[x >= wplus] = "red"
barplot(dsignrank(x,n),names.arg = x,main = paste0("dsignrank(x, n = ", n, ")"),col = colors)
```

## Computations

and using the cumulative distribution function $F_{W^+}(w^+-1,n)$ of our test statistic:

```{r}
plot(x,psignrank(x, n = n),type = "s",main = paste0("psignrank(x, n = ", n, ")"))
abline(v=wplus,col = "red"); abline(h=psignrank(wplus,n),col = "blue")
```

## Computations

we can find the $p$-value using $P_{H_0}(W^+ \ge w^+) = 1 - F_{W^+}(w^+ - 1,n)$:

```{r}
pvalue = 1-psignrank(wplus-1,n,lower.tail = TRUE)
pvalue
```

There is also an R base implementation of this test:

```{r}
wilcox.test(response,alternative="greater")
```

## Conclusion

We can reject the null hypothesis at significance level $\alpha = 0.05$ in favor of the alternative that sending kids to school improves their social awareness.

# Bootstrap Example

## Question

Does small dose of aspirin prevent heart attacks in healthy middle-aged men?

## Experiment

A randomized double-blind study was designed to collect data.   
The subjects were randomly assigned to the aspirin and placebo groups.   
Doctors and subjects didn't know whether they treated or received aspirin or placebo substance.   

```{r}
labels = c("nattacks","nsubjects")
aspirin = c(104,11037)
placebo = c(189,11034)
data = data.frame(aspirin,placebo)
rownames(data) = labels
data
```

## Statistic

Ratio of the rates:

```{r}
rate = function(v) v[1]/v[2]
theta.hat = rate(data$aspirin)/rate(data$placebo)
theta.hat
```

This means that in this sample aspirin-takers only have 55% as many heart attacks as placebo-takers.

## Computations

Is this due to chance?   
Or can this results be reproduced in a repetition of the same experiments?   
Let's use the bootstrap method to find out:

```{r}
population.one = c( rep(1,data["nattacks","aspirin"]), 
                    rep(0,data["nsubjects","aspirin"]-data["nattacks","aspirin"]) )
population.two = c( rep(1,data["nattacks","placebo"]), 
                    rep(0,data["nsubjects","placebo"]-data["nattacks","placebo"]) )

draw.bootstrap.sample = function() {
  boot.pop.one = sample(population.one,replace = TRUE)
  boot.pop.two = sample(population.two,replace = TRUE)
  rate.one = sum(boot.pop.one)/length(boot.pop.one)
  rate.two = sum(boot.pop.two)/length(boot.pop.two)
  return(rate.one/rate.two)
}
```

## Computations

and now simulate:

```{r eval = FALSE}
nrep = 10000
theta.boot = replicate(nrep,draw.bootstrap.sample())
hist(theta.boot,breaks=100)

# sample estimate
abline(v=theta.hat,col = "red",lwd = 4)

# bootstrap confidence interval
confidence.lower = sort(theta.boot)[nrep*.025]
confidence.upper = sort(theta.boot)[nrep*.975]
abline(v=c(confidence.lower,confidence.upper),col = "blue",lwd = 4)
```

## Computations

```{r echo = FALSE}
nrep = 10000
theta.boot = replicate(nrep,draw.bootstrap.sample())
hist(theta.boot,breaks=100)

# sample estimate
abline(v=theta.hat,col = "red",lwd = 4)

# bootstrap confidence interval
confidence.lower = sort(theta.boot)[nrep*.025]
confidence.upper = sort(theta.boot)[nrep*.975]
abline(v=c(confidence.lower,confidence.upper),col = "blue",lwd = 4)
```

## Conclusion

We can conclude that aspirin was found to be significantly beneficial for preventing heart attacks.

# Overall Conclusion

## Summary

* You learned some basics about R
* You saw an example using the ranks of differences instead the actual differences for hypothesis testing
* You saw an example of estimating the uncertainty of a parameter using the bootstrap

## Next Lecture

Closer look at the boostrap and Monte Carlo simulations.

## Homeworks

Homework 1 will be posted soon on the course website.

Deadline is 8 days after posting date.
